---
title: "Lim & Zohren, 2021"
author: "STATS 631, Winter 2026"
format:
  beamer:
    header-includes: |
      \setbeamertemplate{footline}[page number]
    fig_crop: false
---

## Impact

Lim, B., & Zohren, S. (2021). Time-series forecasting with deep learning: a survey. _Philosophical Transactions of the Royal Society A_, 379(2194), 20200209. 
(https://doi.org/10.1098/rsta.2020.0209).

* cited 2500 times

* Philosophical Transactions A (impact factor: 4.3)

* This is a review paper

## Insights

* CNN is like an AR model: finite number of lags of previous data.

* RNN is like an SSM


## The M4 Forecasting Competition

* Hyndman R. (2020). A brief history of forecasting competitions. Int. J. Forecast. 36, 7–14. (doi:10.1016/j.ijforecast.2019.03.015)

* Makridakis, S., Spiliotis, E., & Assimakopoulos, V. (2020). The M4 Competition: 100,000 time series and 61 forecasting methods. International Journal of Forecasting, 36, 54-74. (https://doi.org/10.1016/j.ijforecast.2019.04.014)

* **The clear winner of the M4 forecasting competition**.\
Smyl, S. (2020). A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting. International Journal of Forecasting, 36, 75–85. (https://doi.org/10.1016/j.ijforecast.2019.03.017)

## Smyl (2020) and LSTM

* Uses a combination of exponential smoothing and long short-term memory (LSTM) recurrent neural net (RNN) methods.

* LSTM was state-of-the-art from 2015-2020: Google translate, Apple's Siri, Amazon's Alexa, Facebook translate, OpenAI, DeepMind.

* Achieved prominence by winning a handwriting recognition competition in 2009 (https://en.wikipedia.org/wiki/Long_short-term_memory).

* LSTM Largely addresses the vanishing gradient problem; can have the exploding gradient problem

## Forecasting and science

* How is forecasting related and unrelated to developing useful understanding?


