
```{python}
#| label: q3_03_read_huron_data
#| echo: false
import warnings
import pandas as pd
from statsmodels.tsa.arima.model import ARIMA

dat = pd.read_csv("data/huron_level.csv", comment='#')
huron_level = dat[' Jan'].values  # Note: space before Jan in header
year = dat['Year'].values

# Fit ARMA(2,1) and ARMA(2,2) models
with warnings.catch_warnings():
    warnings.filterwarnings('ignore')
    arma2_1 = ARIMA(huron_level, order=(2, 0, 1),trend='c').fit()
    arma2_2 = ARIMA(huron_level, order=(2, 0, 2),trend='c').fit()

print(arma2_1.summary().tables[0])
print("\n")
print(arma2_2.summary().tables[0])
```

The Python output above uses  `ARIMA` from `statsmodels` to fit ARMA(2,1) and ARMA(2,2) models to the January level (in meters above sea level) of Lake Huron from 1860 to 2024. Residual diagnostics (not shown) show no major violation of model assumptions. We aim to choose one of these as a null hypothesis of no trend for later comparison with models including a trend.

Which is the best conclusion from the available evidence:

A: The ARMA(2,2) model has a lower AIC so it should be preferred.

B:  We cannot reject the null hypothesis of ARMA(2,1) since the ARMA(2,2) model has a likelihood less than 1.92 log units higher than ARMA(2,1). Since there is not sufficient evidence to the contrary, it is better to select the simpler ARMA(2,1) model.

C: Since the comparison of AIC values and the likelihood ratio test come to different conclusions in this case, it is more-or-less equally reasonable to use either model.

D: When the results are borderline, numerical errors in the `stats::arima` optimization may become relevant. We should check using optimization searches from multiple starting points in parameter space, for example, using `arima2::arima`.

